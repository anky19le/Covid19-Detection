{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing necessary libraries\nimport os\nimport time\nimport copy\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport torch,torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, models, transforms\nimport torch.optim as optim\n\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom torch.nn import Parameter","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:12.669743Z","iopub.execute_input":"2022-05-05T14:45:12.670073Z","iopub.status.idle":"2022-05-05T14:45:12.676272Z","shell.execute_reply.started":"2022-05-05T14:45:12.670025Z","shell.execute_reply":"2022-05-05T14:45:12.675123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections.abc import Iterable\n\ndef set_freeze_by_idxs(model, idxs, freeze=True): \n    \"\"\" Function to freeze layers of model during fine-training\"\"\"\n    if not isinstance(idxs, Iterable):\n        idxs = [idxs]\n    num_child = len(list(model.children()))\n    idxs = tuple(map(lambda idx: num_child + idx if idx < 0 else idx, idxs))\n    for idx, child in enumerate(model.children()):\n        if idx not in idxs:\n            continue\n        for param in child.parameters():\n            param.requires_grad = not freeze\n    return model\n            \ndef freeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, True)\n\ndef unfreeze_by_idxs(model, idxs):\n    return set_freeze_by_idxs(model, idxs, False)\n\ndef set_parameter_requires_grad(model):\n    for param in model.parameters():\n        param.requires_grad=False\n    return model\n\ndef initialize_model(model_name, num_classes, use_pretrained, unfreeze_num):\n    \"\"\"Function to intialize various model ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201']\n        and modify output classifier layers according to number of classes, with \"unfreeze_num\" of layers freezed.\n    \"\"\"\n    if model_name=='vgg16':\n        model_pre=models.vgg16(pretrained=use_pretrained) \n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre) \n        num_ftrs=model_pre.classifier[6].in_features # feature_map \n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='vgg19':\n        model_pre=models.vgg19(pretrained=use_pretrained) \n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre) \n        num_ftrs=model_pre.classifier[6].in_features\n        model_pre.classifier[6]=nn.Linear(num_ftrs,num_classes) \n        if unfreeze_num==1:\n            unfreeze=[-1]\n        elif unfreeze_num==2:\n            unfreeze=[-1,-3]\n        elif unfreeze_num==3:\n            unfreeze=[-1,-3,-5]\n        else:\n            unfreeze=[-1,-3,-5,-7]\n        model_pre.features=unfreeze_by_idxs(model_pre.features,unfreeze)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet101':\n        model_pre=models.resnet101(pretrained=use_pretrained) \n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features \n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='resnet152':\n        model_pre=models.resnet152(pretrained=use_pretrained) \n        model_pre.conv1.in_channels=1\n        model_pre.conv1.weight=Parameter(model_pre.conv1.weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.fc.in_features\n        model_pre.fc=nn.Linear(num_ftrs,num_classes)\n\n        for i in range(unfreeze_num):\n            model_pre.layer4=unfreeze_by_idxs(model_pre.layer4,-i)\n        for param in model_pre.fc.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet161':\n        model_pre=models.densenet161(pretrained=use_pretrained)\n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features \n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        \n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    elif model_name=='densenet201':\n        model_pre=models.densenet201(pretrained=use_pretrained)\n        model_pre.features[0].in_channels=1\n        model_pre.features[0].weight=Parameter(model_pre.features[0].weight[:,1:2,:,:])\n        model_pre=set_parameter_requires_grad(model_pre)\n        num_ftrs=model_pre.classifier.in_features \n        model_pre.classifier=nn.Linear(num_ftrs,num_classes)\n        for i in range(unfreeze_num):\n            model_pre.features.denseblock4=unfreeze_by_idxs(model_pre.features.denseblock4,-i)\n        for param in model_pre.classifier.parameters():\n            param.requires_grad=True\n        input_size=224\n    else:\n        print('model not implemented')\n        return None,None\n    return model_pre, input_size","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:13.112769Z","iopub.execute_input":"2022-05-05T14:45:13.113111Z","iopub.status.idle":"2022-05-05T14:45:13.151456Z","shell.execute_reply.started":"2022-05-05T14:45:13.113076Z","shell.execute_reply":"2022-05-05T14:45:13.150532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nmodel_all = []\ndir = '.'\n\ndef auto_net(model_name, num_classes, use_pretrained, unfreeze_num):\n    \"\"\" Function to prepare model using \"initialize_model\" method and saving their models with weights.\n        saved weights will be saved at '/{model_name}/{model_name}_{unfeeze_num}.pth'\"\"\"\n    model_all = []\n    for k in range(unfreeze_num):\n        model, input_size = initialize_model(model_name, num_classes, use_pretrained, k+1)\n        my_path = Path(dir + '/{}'.format(model_name))\n        if not my_path.is_dir():    \n            os.mkdir(my_path)\n        torch.save(model, dir + '/{}/{}_{}.pth'.format(model_name, model_name, k)) \n        model_all.append(model)\n    return model_all\n\nmodel_name = ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] \n\n# using densenet161 as our model\n# can experiment with other models\nmodel_all = auto_net(model_name[4], num_classes=3, use_pretrained=False, unfreeze_num=4)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:13.154911Z","iopub.execute_input":"2022-05-05T14:45:13.155261Z","iopub.status.idle":"2022-05-05T14:45:16.235237Z","shell.execute_reply.started":"2022-05-05T14:45:13.155235Z","shell.execute_reply":"2022-05-05T14:45:16.234084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\n# Training dataframe\ntrain_df = pd.read_csv('../input/covidxct/train_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntrain_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntrain_df=train_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\n# Validation dataframe\nval_df = pd.read_csv('../input/covidxct/val_COVIDx_CT-2A.txt', sep=\" \", header=None)\nval_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\nval_df=val_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )\n\n# Testing dataframe\ntest_df = pd.read_csv('../input/covidxct/test_COVIDx_CT-2A.txt', sep=\" \", header=None)\ntest_df.columns=['filename', 'label', 'xmin','ymin','xmax','ymax']\ntest_df=test_df.drop(['xmin', 'ymin','xmax', 'ymax'], axis=1 )","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.239754Z","iopub.execute_input":"2022-05-05T14:45:16.240029Z","iopub.status.idle":"2022-05-05T14:45:16.447652Z","shell.execute_reply.started":"2022-05-05T14:45:16.24Z","shell.execute_reply":"2022-05-05T14:45:16.446483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.449335Z","iopub.execute_input":"2022-05-05T14:45:16.449686Z","iopub.status.idle":"2022-05-05T14:45:16.460435Z","shell.execute_reply.started":"2022-05-05T14:45:16.449648Z","shell.execute_reply":"2022-05-05T14:45:16.458657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_path = '../input/covidxct/2A_images/'  # directory path of images\ntrain_df['filename'] = image_path + train_df['filename']\nval_df['filename'] = image_path + val_df['filename']\ntest_df['filename'] = image_path + test_df['filename']\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.461538Z","iopub.execute_input":"2022-05-05T14:45:16.461789Z","iopub.status.idle":"2022-05-05T14:45:16.51233Z","shell.execute_reply.started":"2022-05-05T14:45:16.461764Z","shell.execute_reply":"2022-05-05T14:45:16.511292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Balancing the training and validation datastets","metadata":{}},{"cell_type":"code","source":"N = train_df[train_df['label'] == 0]\nP = train_df[train_df['label'] == 1]\nC = train_df[train_df['label'] == 2]\n\nfrom sklearn.utils import resample\n\nN_download = resample(N, replace = True, n_samples = 25496, random_state=0)\nC_download = resample(C, replace = True, n_samples = 25496, random_state=0)\ntrain_df = pd.concat([N_download, P, C_download])\ntrain_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.513784Z","iopub.execute_input":"2022-05-05T14:45:16.514154Z","iopub.status.idle":"2022-05-05T14:45:16.544723Z","shell.execute_reply.started":"2022-05-05T14:45:16.514119Z","shell.execute_reply":"2022-05-05T14:45:16.543975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N_v = val_df[val_df['label'] == 0]\nP_v = val_df[val_df['label'] == 1]\nC_v = val_df[val_df['label'] == 2]\n\nfrom sklearn.utils import resample\n\nN_v_download = resample(N_v, replace = True, n_samples = 6244,random_state=0)\nP_v_download = resample(P_v, replace = True, n_samples = 6244,random_state=0)\nval_df = pd.concat([N_v_download, P_v_download, C_v])\n\nval_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.545916Z","iopub.execute_input":"2022-05-05T14:45:16.546262Z","iopub.status.idle":"2022-05-05T14:45:16.565857Z","shell.execute_reply.started":"2022-05-05T14:45:16.546227Z","shell.execute_reply":"2022-05-05T14:45:16.564906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = shuffle(train_df) \nval_df = shuffle(val_df)\ntest_df = shuffle(test_df)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.5686Z","iopub.execute_input":"2022-05-05T14:45:16.568911Z","iopub.status.idle":"2022-05-05T14:45:16.588704Z","shell.execute_reply.started":"2022-05-05T14:45:16.568879Z","shell.execute_reply":"2022-05-05T14:45:16.587946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = {0:'Normal',1:'Pneumonia',2:'COVID-19'}\nclass_names = ['Normal','Pneumonia','COVID-19']\n\ntrain_df['label_n'] = [labels[b] for b in train_df['label']]\nval_df['label_n'] = [labels[b] for b in val_df['label']]\ntest_df['label_n'] = [labels[b] for b in test_df['label']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.590635Z","iopub.execute_input":"2022-05-05T14:45:16.590979Z","iopub.status.idle":"2022-05-05T14:45:16.6357Z","shell.execute_reply.started":"2022-05-05T14:45:16.590942Z","shell.execute_reply":"2022-05-05T14:45:16.634963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Negative and positive values of train: \\n{train_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of validation: \\n{val_df['label_n'].value_counts()}\")\nprint(f\"Negative and positive values of test: \\n{test_df['label_n'].value_counts()}\")","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.636825Z","iopub.execute_input":"2022-05-05T14:45:16.637167Z","iopub.status.idle":"2022-05-05T14:45:16.671536Z","shell.execute_reply.started":"2022-05-05T14:45:16.637133Z","shell.execute_reply":"2022-05-05T14:45:16.670734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.reset_index()\nval_df=val_df.reset_index()\ntest_df=test_df.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.672629Z","iopub.execute_input":"2022-05-05T14:45:16.672943Z","iopub.status.idle":"2022-05-05T14:45:16.68555Z","shell.execute_reply.started":"2022-05-05T14:45:16.67291Z","shell.execute_reply":"2022-05-05T14:45:16.684733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CovidDataset(Dataset):\n    def __init__(self, dataset_df, transform=None):\n        self.dataset_df = dataset_df\n        self.transform = transform\n        \n    def __len__(self):\n        return self.dataset_df.shape[0]\n    \n    def __getitem__(self, idx):\n        image_name = self.dataset_df['filename'][idx]\n        img = Image.open(image_name)\n        label = self.dataset_df['label'][idx]\n        \n        if self.transform:\n            img = self.transform(img)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.686835Z","iopub.execute_input":"2022-05-05T14:45:16.687474Z","iopub.status.idle":"2022-05-05T14:45:16.694089Z","shell.execute_reply.started":"2022-05-05T14:45:16.687439Z","shell.execute_reply":"2022-05-05T14:45:16.693249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training variables and hyperparamater\nbatch_size = 64\ninput_channel = 1\ninput_size = (224,224)\ncrop_size = (340,380)\nnum_classes = 3\nnum_epochs = 5","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.695387Z","iopub.execute_input":"2022-05-05T14:45:16.696051Z","iopub.status.idle":"2022-05-05T14:45:16.702919Z","shell.execute_reply.started":"2022-05-05T14:45:16.695996Z","shell.execute_reply":"2022-05-05T14:45:16.702082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image transformations \ntransform = {\n    'train':transforms.Compose([\n        transforms.RandomHorizontalFlip(p=0.5), # Image augmentations for training\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomRotation(30),\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n        transforms.Normalize([0.6349431],[0.32605055])\n    ]),\n    'test':transforms.Compose([\n        transforms.CenterCrop(crop_size),\n        transforms.Resize(input_size),\n        transforms.Grayscale(input_channel),\n        transforms.ToTensor(),\n        transforms.Normalize([0.63507175],[0.3278614])\n    ])\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.705653Z","iopub.execute_input":"2022-05-05T14:45:16.705925Z","iopub.status.idle":"2022-05-05T14:45:16.714841Z","shell.execute_reply.started":"2022-05-05T14:45:16.705897Z","shell.execute_reply":"2022-05-05T14:45:16.714069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_names = ['train','val','test']\nimage_transforms = {'train':transform['train'], 'val':transform['test'],'test':transform['test']}\n\ntrain_dataset = CovidDataset(train_df, transform=image_transforms['train'])\nval_dataset = CovidDataset(val_df, transform=image_transforms['val'])\ntest_dataset = CovidDataset(test_df, transform=image_transforms['test'])\n\nimage_dataset = {'train':train_dataset, 'val':val_dataset,'test':test_dataset}\n\ndataloaders = {x:DataLoader(image_dataset[x],batch_size=batch_size,shuffle=True,num_workers=4) for x in dataset_names}\n\ndataset_sizes = {x:len(image_dataset[x]) for x in dataset_names}\n\nprint(dataset_sizes)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.717635Z","iopub.execute_input":"2022-05-05T14:45:16.717942Z","iopub.status.idle":"2022-05-05T14:45:16.729702Z","shell.execute_reply.started":"2022-05-05T14:45:16.717918Z","shell.execute_reply":"2022-05-05T14:45:16.728597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom PIL import Image\n\ndef show_tensor_img(tensor_img):\n    img=transforms.ToPILImage()(tensor_img)\n    plt.figure()\n    plt.imshow(img,plt.cm.gray)\n    plt.show()\n\n# Displaying some sample images from train dataset\nfor i in range(4):\n    show_tensor_img(train_dataset[i][0])","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:16.731747Z","iopub.execute_input":"2022-05-05T14:45:16.732469Z","iopub.status.idle":"2022-05-05T14:45:17.386961Z","shell.execute_reply.started":"2022-05-05T14:45:16.732385Z","shell.execute_reply":"2022-05-05T14:45:17.386144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    cm=cm.numpy()\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        cm=cm.astype('int')\n        print('Confusion matrix, without normalization')\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    fmt = '{:.2f}' if normalize else '{}'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n      plt.text(i, j, fmt.format(cm[i, j]),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\n\ndef confusion_matrix(preds, labels, conf_matrix):\n    preds = torch.argmax(preds, 1)\n    for p, t in zip(preds, labels):\n        conf_matrix[t, p] += 1\n    return conf_matrix\n\ndef calculate_all_prediction(conf_matrix):\n    total_sum = conf_matrix.sum()\n    correct_sum = (np.diag(conf_matrix)).sum()\n    prediction = round(100*float(correct_sum)/float(total_sum),2)\n    return prediction\n \ndef calculate_label_prediction(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=0)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    prediction = 0\n    if label_total_sum != 0:\n        prediction = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return prediction\n \ndef calculate_label_recall(conf_matrix,labelidx):\n    label_total_sum = conf_matrix.sum(axis=1)[labelidx]\n    label_correct_sum = conf_matrix[labelidx][labelidx]\n    recall = 0\n    if label_total_sum != 0:\n        recall = round(100*float(label_correct_sum)/float(label_total_sum),2)\n    return recall\n \ndef calculate_f1(prediction,recall):\n    if (prediction+recall)==0:\n        return 0\n    return round(2*prediction*recall/(prediction+recall),2)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:17.388372Z","iopub.execute_input":"2022-05-05T14:45:17.388902Z","iopub.status.idle":"2022-05-05T14:45:17.404483Z","shell.execute_reply.started":"2022-05-05T14:45:17.388854Z","shell.execute_reply":"2022-05-05T14:45:17.403623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_model_path = './densenet161/densenet161_3.pth'\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel_name = ['vgg16','vgg19','resnet101','resnet152','densenet161','densenet201'] \n\n# using densenet161 as our model\n# can experiment with other models\nmodel = torch.load(pretrained_model_path)\nmodel = model.to(device)\n\ncriterion=nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam( model.parameters(), lr=0.0001,betas=(0.9, 0.999))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-05T14:45:17.405735Z","iopub.execute_input":"2022-05-05T14:45:17.406117Z","iopub.status.idle":"2022-05-05T14:45:22.063928Z","shell.execute_reply.started":"2022-05-05T14:45:17.406067Z","shell.execute_reply":"2022-05-05T14:45:22.063093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm # for progess bar\n\ndef train(model, epoch, num_epochs, criterion,optimizer):\n    model.train()\n    print('-' * 100)\n    #print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n    running_loss = 0.0\n    running_corrects = 0\n    with tqdm(dataloaders['train'], unit=\"batch\") as tepoch:\n        for idx, (inputs, labels) in enumerate(tepoch):\n            tepoch.set_description(f\"Epoch {epoch}\")\n\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs) \n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels) \n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            acc = torch.sum(preds == labels.data)/batch_size * 100.0\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n            tepoch.set_postfix(loss=loss.item(), acc = acc)\n\n    epoch_loss = running_loss / dataset_sizes['train']\n    epoch_acc = running_corrects.double() / dataset_sizes['train']\n    print('train_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:22.065385Z","iopub.execute_input":"2022-05-05T14:45:22.065732Z","iopub.status.idle":"2022-05-05T14:45:22.075348Z","shell.execute_reply.started":"2022-05-05T14:45:22.065696Z","shell.execute_reply":"2022-05-05T14:45:22.074447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(model,epoch,num_epochs,criterion,optimizer,best_acc):\n    model.eval()\n    running_loss = 0.0\n    running_corrects = 0\n    best_acc=best_acc\n    best_model_wts=copy.deepcopy(model.state_dict())\n    conf_matrix = torch.zeros(num_classes, num_classes) \n    with torch.no_grad():\n        for idx, (inputs, labels) in enumerate(dataloaders['val']):\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            loss = criterion(outputs, labels)\n            conf_matrix = confusion_matrix(outputs, labels, conf_matrix) \n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data) \n\n        plot_confusion_matrix(conf_matrix, classes=class_names, normalize=False, title='confusion matrix') \n\n    epoch_loss = running_loss / dataset_sizes['val'] \n    epoch_acc = running_corrects.double() / dataset_sizes['val'] \n    print('val_total Loss: {:.4f} Acc: {:.4f}%'.format( epoch_loss, epoch_acc*100))\n\n    all_prediction = calculate_all_prediction(conf_matrix) \n    print('all_prediction:{}'.format(all_prediction))\n    label_prediction = [] \n    label_recall = [] \n    for i in range(num_classes):\n        label_prediction.append(calculate_label_prediction(conf_matrix,i))\n        label_recall.append(calculate_label_recall(conf_matrix,i))\n\n    keys=class_names\n    values=list(range(num_classes))\n    dictionary = dict(zip(keys, values))\n    for ei,i in enumerate(dictionary):\n        print(ei,'\\t',i,'\\t','prediction=',label_prediction[ei],'%,\\trecall=',label_recall[ei],'%,\\tf1=',calculate_f1(label_prediction[ei],label_recall[ei])) # 输出每个类的，精确率，召回率，F1\n    p = round(np.array(label_prediction).sum()/len(label_prediction),2) \n    r = round(np.array(label_recall).sum()/len(label_prediction),2) \n    print('MACRO-averaged:\\nprediction=',p,'%,recall=',r,'%,f1=',calculate_f1(p,r)) \n\n#     print(epoch_acc.tpye)\n#     print(best_acc.type)\n    if epoch_acc > best_acc:\n        best_acc=epoch_acc.item()\n        best_model_wts=copy.deepcopy(model.state_dict())\n\n    return best_model_wts,best_acc,epoch_acc.item()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:22.076859Z","iopub.execute_input":"2022-05-05T14:45:22.077433Z","iopub.status.idle":"2022-05-05T14:45:22.092641Z","shell.execute_reply.started":"2022-05-05T14:45:22.077394Z","shell.execute_reply":"2022-05-05T14:45:22.091694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import copy\n\nnum_epochs = 5\n\nif __name__ == '__main__':\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    acc=[]\n    for epoch in range(num_epochs):\n        train(model,epoch,num_epochs,criterion,optimizer)\n        best_model_wts,best_acc,epoch_acc=test(model, epoch, num_epochs, criterion, optimizer, best_acc)\n        acc.append(epoch_acc)\n    print('*' * 100)\n    print('best_acc:{}'.format(best_acc))\n    print('*' * 100)\n    torch.save(best_model_wts, 'densenet201_3_model_best_acc.pth')","metadata":{"execution":{"iopub.status.busy":"2022-05-05T14:45:22.094991Z","iopub.execute_input":"2022-05-05T14:45:22.095574Z","iopub.status.idle":"2022-05-05T15:39:25.382011Z","shell.execute_reply.started":"2022-05-05T14:45:22.095529Z","shell.execute_reply":"2022-05-05T15:39:25.3793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(acc)","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:39:25.390106Z","iopub.execute_input":"2022-05-05T15:39:25.390466Z","iopub.status.idle":"2022-05-05T15:39:25.403237Z","shell.execute_reply.started":"2022-05-05T15:39:25.390427Z","shell.execute_reply":"2022-05-05T15:39:25.402442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x=range(len(acc))\ny=acc\nplt.figure()\nplt.title('densenet201_3_acc_lr=0.0001')\nplt.plot(x,y)\nplt.savefig('mini64_lr0.0001_e20_densenet201_3_acc.jpg')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-05T15:39:25.410552Z","iopub.execute_input":"2022-05-05T15:39:25.412637Z","iopub.status.idle":"2022-05-05T15:39:25.675747Z","shell.execute_reply.started":"2022-05-05T15:39:25.412598Z","shell.execute_reply":"2022-05-05T15:39:25.674911Z"},"trusted":true},"execution_count":null,"outputs":[]}]}